{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Cykj-q7h5bM"
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcF8cgWTh1B3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import time\n",
    "import json\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_INDEX=5\n",
    "isGPU = True\n",
    "\n",
    "\n",
    "isTest=''\n",
    "# isTest = 'test-'\n",
    "# isTest = 'new-'\n",
    "\n",
    "# MODEL_NAME = \"resnet\"\n",
    "MODEL_NAME = \"lenet5\"\n",
    "\n",
    "############################\n",
    "\n",
    "NUM_EPOCHES = 40\n",
    "NUM_CLASS = 100\n",
    "EPOCH_THRES=5\n",
    "BATCH_SIZE=256\n",
    "\n",
    "DATA_NAME=\"cifar\"\n",
    "\n",
    "\n",
    "DATA_DIR = f'./data/{DATA_NAME}-{NUM_CLASS}'\n",
    "\n",
    "\n",
    "############################\n",
    "\n",
    "# thresholds = [[0.1], [0.2],[0.3], [0.4], [0.5], [0.6], [0.7],[0.8], [0.9]]\n",
    "# to_keep = [[False, True]]*len(thresholds)\n",
    "\n",
    "\n",
    "# thresholds = [[0.1, 0.9], [0.2, 0.8], [0.3, 0.7]]\n",
    "# to_keep = [[False, True, True] , [False, True, True], [False, True, True]]\n",
    "\n",
    "# thresholds = [[0.1, 0.3, 0.7], [0.15, 0.5, 0.85]]\n",
    "# to_keep = [[False, True, True, False], [False, True, True, False]]\n",
    "\n",
    "\n",
    "\n",
    "thresholds = [[0.1], [0.2], [0.2, 0.8], [0.15, 0.5, 0.85], [0.1, 0.4, 0.7]]\n",
    "to_keep = [[False, True], [False, True], [False, True, True], [False, True, True, False], [False, True, True, False]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f'\\n\\nRUNNING NOTEBOOK MODEL : {isTest}{MODEL_NAME}, DATA: {DATA_NAME}-{NUM_CLASS}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # HF model\n",
    "# HF_API_TOKEN = os.getenv(\"HF_API_TOKEN\")\n",
    "\n",
    "\n",
    "if isGPU:\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" ## to avoid Context Switching \n",
    "    os.environ[\"HF_HOME\"]= \"/data2/meithnav/.hfcache/\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(GPU_INDEX) # not changing GPU. Only \n",
    "    os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(GPU_INDEX) # not changing GPU. Only \n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "if isGPU:\n",
    "    torch.cuda.set_device(0) ## setgpu\n",
    "    print(\"\\n\\n--> CONNECTED TO GPU NO: \", torch.cuda.current_device())\n",
    "    print(\"--> GPU_INDEX: \", GPU_INDEX)\n",
    "        \n",
    "    # GPU (MPS for Apple Silicon, CUDA for Nvidia GPUs, or CPU)\n",
    "\n",
    "    torch.cuda.empty_cache() # clear GPU cache\n",
    "    torch.cuda.reset_max_memory_allocated()\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# APPEND ROOT DIRECTORY\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.path.dirname('Forgetability Experiments'), '..')))\n",
    "\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "os.makedirs(f'./models/{isTest}{MODEL_NAME}-{DATA_NAME}-{NUM_CLASS}' ,  exist_ok=True)\n",
    "os.makedirs('./outputs',  exist_ok=True)\n",
    "os.makedirs('./outputs/plots',  exist_ok=True)\n",
    "os.makedirs(f'./outputs/plots/{isTest}{MODEL_NAME}-{DATA_NAME}-{NUM_CLASS}',  exist_ok=True)\n",
    "os.makedirs('./outputs/results',  exist_ok=True)\n",
    "os.makedirs(f'./outputs/results/{isTest}{MODEL_NAME}-{DATA_NAME}-{NUM_CLASS}' ,  exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            correct += (predictions == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QvvtnU1eh8ak"
   },
   "outputs": [],
   "source": [
    "class ForgetabilityTracker:\n",
    "    def __init__(self, dataset_size):\n",
    "        self.misclassification_counts = np.zeros(dataset_size, dtype=np.int32)\n",
    "\n",
    "    def update(self, predictions, labels, indices, subset_mapping=None):\n",
    "        incorrect_predictions = predictions != labels\n",
    "        incorrect_predictions = incorrect_predictions.cpu().numpy()\n",
    "        indices = indices.cpu().numpy()\n",
    "        \n",
    "        if subset_mapping is not None:\n",
    "            # Map indices from subset to original dataset\n",
    "            indices = subset_mapping[indices]\n",
    "        \n",
    "        self.misclassification_counts[indices] += incorrect_predictions\n",
    "\n",
    "    def get_scores(self):\n",
    "        return self.misclassification_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(data, title=\"Distribution Plot\", xlabel=\"Values\", ylabel=\"Frequency\", kde=True, path='./'):\n",
    "   \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.kdeplot(data, fill=True, color=\"blue\", alpha=0.7, bw_adjust=0.5)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel(ylabel, fontsize=12)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.savefig(f'{path}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFawbq8tio01"
   },
   "source": [
    "LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hnw0VXKOiFzc"
   },
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(nn.MaxPool2d(2)(self.conv1(x)))\n",
    "        x = torch.relu(nn.MaxPool2d(2)(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Skip connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = torch.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASS):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        # Initial Convolutional Layer\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, NUM_CLASS)\n",
    "\n",
    "    def _make_layer(self, out_channels, blocks, stride):\n",
    "        strides = [stride] + [1] * (blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(BasicBlock(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpB1ujCymzFQ"
   },
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, train_loader, test_loader, tracker=None, epoch_threshold=5, thresholds_arr=None, to_keep=None, num_epochs = NUM_EPOCHES):\n",
    "    \n",
    "    current_loader = train_loader  # Use the initial loader for the first phase\n",
    "    results = {\n",
    "        \"time\":[],\n",
    "        \"accuracy\":[],\n",
    "        \"size\":[]\n",
    "    }\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        start_ep = time.time()\n",
    "        model.train()\n",
    "\n",
    "        # Training loop\n",
    "        for batch_idx, (data, targets) in tqdm(\n",
    "            enumerate(current_loader), desc=f\"Epoch {epoch + 1}/{num_epochs}\"\n",
    "        ):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if tracker:\n",
    "                # Handle subset mapping for indices\n",
    "                if isinstance(current_loader.dataset, Subset):\n",
    "                    subset_mapping = np.array(current_loader.dataset.indices)\n",
    "                else:\n",
    "                    subset_mapping = None\n",
    "\n",
    "                batch_indices = batch_idx * current_loader.batch_size + torch.arange(data.size(0)).to(device)\n",
    "                tracker.update(predictions, targets, batch_indices, subset_mapping=subset_mapping)\n",
    "\n",
    "        \n",
    "        \n",
    "        # Update dataset every `epoch_threshold` epochs if tracker is enabled\n",
    "        if tracker and thresholds_arr and (epoch + 1) % epoch_threshold == 0:\n",
    "            # print(f\"Epoch {epoch + 1}: Evaluating forgetability and updating dataset...\")\n",
    "\n",
    "            \n",
    "            # Get forgetability scores and normalize\n",
    "            forgetability_scores = tracker.get_scores()\n",
    "            # print(forgetability_scores)\n",
    "            # print(len(forgetability_scores))\n",
    "            \n",
    "            normalized_scores = (forgetability_scores - np.min(forgetability_scores)) / (np.max(forgetability_scores) - np.min(forgetability_scores))\n",
    "\n",
    "            # normalized_scores = forgetability_scores / (epoch+1)\n",
    "            \n",
    "            plot_distribution(normalized_scores, title=\"Forgettability Scores Distribution\", xlabel=\"Values\", ylabel=\"Density\", path=f'./outputs/plots/{isTest}{MODEL_NAME}-{DATA_NAME}-{NUM_CLASS}/Distri-Plot-{epoch+1}' )\n",
    "            \n",
    "            # Multi-threshold case: Create distinct bins\n",
    "            bin_indices = []\n",
    "            for i, threshold in enumerate(thresholds_arr):\n",
    "                if i == 0:\n",
    "                    bin_indices.append(np.where(normalized_scores <= threshold)[0])\n",
    "                else:\n",
    "                    bin_indices.append(\n",
    "                        np.where((normalized_scores > thresholds_arr[i - 1]) & (normalized_scores <= threshold))[0]\n",
    "                    )\n",
    "            bin_indices.append(np.where(normalized_scores > thresholds_arr[-1])[0])\n",
    "\n",
    "            # Filter bins based on `to_keep`\n",
    "            if to_keep is not None:\n",
    "                if len(to_keep) != len(bin_indices):\n",
    "                    raise ValueError(\n",
    "                        f\"Invalid `to_keep` length. Expected {len(bin_indices)} booleans, but got {len(to_keep)}.\"\n",
    "                    )\n",
    "                bin_indices = [bin for bin, keep in zip(bin_indices, to_keep) if keep]\n",
    "\n",
    "            indices_to_keep = np.concatenate(bin_indices) if bin_indices else np.array([], dtype=int)\n",
    "            # print(f\"\\n\\n-> Keeping {len(indices_to_keep)} out of {len(forgetability_scores)} datapoints.\")\n",
    "\n",
    "            # Create a mapping from subset indices to original dataset indices\n",
    "            subset_mapping = indices_to_keep\n",
    "\n",
    "            # Update the training dataset\n",
    "            current_loader = DataLoader(\n",
    "                Subset(train_loader.dataset, indices_to_keep),\n",
    "                batch_size=train_loader.batch_size,\n",
    "                shuffle=True\n",
    "            )\n",
    "\n",
    "\n",
    "        end_ep = time.time()\n",
    "\n",
    "        \n",
    "        accuracy_ep = evaluate_model(model, test_loader)\n",
    "        results['time'].append(end_ep - start_ep)\n",
    "        results['accuracy'].append(accuracy_ep)\n",
    "        results['size'].append(len(current_loader.dataset))\n",
    "        \n",
    "        \n",
    "        print(f\"-> EPOCH {epoch+1}, TEST ACCURACY: {accuracy_ep*100:.4f}%, TIME: {end_ep-start_ep:.3f} sec\\n\")\n",
    "        if tracker and thresholds_arr and (epoch + 1) % epoch_threshold == 0:\n",
    "            print(f\"Epoch {epoch + 1}: Evaluating forgetability and updating dataset...\")\n",
    "            print(f\"\\n\\n-> Keeping {len(indices_to_keep)} out of {len(forgetability_scores)} datapoints.\")\n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "    return results\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8pamxH6nBI_"
   },
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_DuUI82em5wm",
    "outputId": "1aafaa05-b340-4f90-9363-2f8b370732e4"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "if NUM_CLASS==10:\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True, download=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=transform)\n",
    "elif NUM_CLASS==100: \n",
    "    train_dataset = torchvision.datasets.CIFAR100(root=DATA_DIR, train=True, download=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.CIFAR100(root=DATA_DIR, train=False, download=True, transform=transform)\n",
    "else: \n",
    "    train_dataset=None\n",
    "    test_dataset=None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_NAME == \"resnet\": \n",
    "    model= ResNet18(num_classes=NUM_CLASS).to(device)\n",
    "\n",
    "elif MODEL_NAME == \"lenet5\":\n",
    "    model= LeNet5(num_classes=NUM_CLASS).to(device)\n",
    "else: \n",
    "    model= None\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "results_array = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K0ugUtDvnFAh",
    "outputId": "72409cf7-24f7-4eca-cd62-45a17795a096"
   },
   "outputs": [],
   "source": [
    "### BASELINE Train on the entire dataset\n",
    "\n",
    "print(f\"\\n\\n****\\nTraining baseline model: {MODEL_NAME}...\")\n",
    "start = time.time()\n",
    "results = train_model(model, optimizer, criterion, train_loader, test_loader)\n",
    "end = time.time()\n",
    "accuracy= evaluate_model(model, test_loader)\n",
    "results_array[ \"baseline\" ] = results\n",
    "\n",
    "print(f\"\\n\\n -> BASELINE TEST ACCURACY: {accuracy*100:.4f}%,, TIME: {end-start:.3f} sec\\n\")\n",
    "print( f'{isTest}{MODEL_NAME}-{DATA_NAME}-{NUM_CLASS}-strategy-{ \"-\".join(map(str, to_keep[0])) }' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing for thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ahz_C4b-ao7o"
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "training_time =[]\n",
    "times = []\n",
    "\n",
    "for idx, thres in tqdm(enumerate(thresholds)):\n",
    "    print(f\"\\n\\n\\n\\n********\\n-> RUNNING THRESHOLD: {thres}, MODEL: {MODEL_NAME}, DATASET: {DATA_NAME}-{NUM_CLASS}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    start = time.time()\n",
    "    # Initialize the model, optimizer, and loss function\n",
    "    \n",
    "    if MODEL_NAME == \"resnet\": \n",
    "        model_dynamic = ResNet18(num_classes=NUM_CLASS).to(device)\n",
    "\n",
    "    elif MODEL_NAME == \"lenet5\":\n",
    "        model_dynamic = LeNet5(num_classes=NUM_CLASS).to(device)\n",
    "    else: \n",
    "        model= None\n",
    "\n",
    "    \n",
    "    optimizer_dynamic = optim.Adam(model_dynamic.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initialize the tracker\n",
    "    tracker_dynamic = ForgetabilityTracker(len(train_dataset))\n",
    "\n",
    "    # Train the model\n",
    "    results = train_model(\n",
    "        model_dynamic, optimizer_dynamic, criterion,\n",
    "        train_loader, test_loader, tracker_dynamic,\n",
    "        epoch_threshold=EPOCH_THRES, thresholds_arr=thres,\n",
    "        to_keep=to_keep[idx]\n",
    "    )\n",
    "\n",
    "    end = time.time()\n",
    "    # Evaluate the model\n",
    "    accuracy_dynamic = evaluate_model(model_dynamic, test_loader)\n",
    "    accuracies.append(accuracy_dynamic)\n",
    "    results_array[\"-\".join(map(str, thres))] = results\n",
    "    times.append(end-start)\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(model_dynamic, f'./models/{isTest}{MODEL_NAME}-{DATA_NAME}-{NUM_CLASS}/thres-{ \"-\".join(map(str, thres)) }-strategy-{ \"-\".join(map(str, to_keep[idx])) }.pt')\n",
    "\n",
    "\n",
    "    print(f\"-> TEST ACCURACY: {accuracy_dynamic}, THRESHOLD: {thres}, TIME: {end-start:.3f} sec\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'./results/{isTest}{MODEL_NAME}-{DATA_NAME}-{NUM_CLASS}/proposed-results-strategy-{ \"-\".join(map(str, to_keep[0])) }.json', 'w') as f:\n",
    "#     json.dump(results_array, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"THRESHOLDS : \" , thresholds)\n",
    "# print(\"ACCURACIES : \" , accuracies)\n",
    "# print(\"TIME TAKEN\", times)\n",
    "# print( f'{isTest}{MODEL_NAME}-{DATA_NAME}-{NUM_CLASS}-strategy-{ \"-\".join(map(str, to_keep[0])) }' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8GeYt7vnPeL"
   },
   "outputs": [],
   "source": [
    "# plt.plot(thresholds, accuracies)\n",
    "# plt.xlabel('Threshold')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Accuracy vs Threshold')\n",
    "# plt.savefig(f'./outputs/plots/{isTest}{MODEL_NAME}-{DATA_NAME}-{NUM_CLASS}/strategy-{ \"-\".join(map(str, to_keep[0])) }.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROPOSED STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch_numbers = [14, 16, 10]\n",
    "# threshold = [0.2, 0.8]\n",
    "# strategy_arr = [[True, True, True], [False, True, False], [False, False, True]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposed_cpt(\n",
    "    epochs,\n",
    "    threshold,\n",
    "    strategies,\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    epoch_threshold=5,\n",
    "):\n",
    "    train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, BATCH_SIZE, shuffle=True)\n",
    "    results = {\n",
    "                \"time\":[],\n",
    "               \"size\":[],\n",
    "               \"accuracy\":[]\n",
    "            }\n",
    "\n",
    "    if MODEL_NAME == \"resnet\": \n",
    "        model= ResNet18(num_classes=NUM_CLASS).to(device)\n",
    "\n",
    "    elif MODEL_NAME == \"lenet5\":\n",
    "        model= LeNet5(num_classes=NUM_CLASS).to(device)\n",
    "    else: \n",
    "        model= None\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    start = time.time()\n",
    "    tracker = ForgetabilityTracker(len(train_loader.dataset))\n",
    "    for i in range(len(epochs)):\n",
    "        t_result = train_model(\n",
    "                                            model,\n",
    "                                            optimizer,\n",
    "                                            criterion,\n",
    "                                            train_loader,\n",
    "                                            test_loader,\n",
    "                                            tracker,\n",
    "                                            epoch_threshold,\n",
    "                                            threshold,\n",
    "                                            strategies[i],\n",
    "                                            epochs[i],\n",
    "                                )\n",
    "        results['time'].extend(t_result['time'])\n",
    "        results['accuracy'].extend(t_result['accuracy'])\n",
    "        results['size'].extend(t_result['size'])\n",
    "        \n",
    "    end = time.time()\n",
    "    accuracy_dynamic = evaluate_model(model, test_loader)\n",
    "    # results_array[\"-\".join(map(str, thres))] = results\n",
    "    # times.append(end-start)\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(model, f'./models/{isTest}{MODEL_NAME}-{DATA_NAME}-{NUM_CLASS}/proposed-thres-{ \"-\".join(map(str, threshold)) }.pt')\n",
    "\n",
    "    print(f\"-> TEST ACCURACY: {accuracy_dynamic}, THRESHOLD: {threshold}, TIME: {end-start:.3f} sec\\n\")\n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = proposed_result = proposed_cpt(\n",
    "    [10, 16, 14],\n",
    "    [0.2, 0.8],\n",
    "    [[True, True, False], [False, True, False], [False, False, True]],\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    epoch_threshold=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_array[\"proposed_cpt\"] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./outputs/results/{isTest}{MODEL_NAME}-{DATA_NAME}-{NUM_CLASS}/results-strategy-{ \"-\".join(map(str, to_keep[0])) }.json', 'w') as f:\n",
    "    json.dump(results_array, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = results_array\n",
    "# Prepare data for plotting\n",
    "configs = list(data.keys())  # e.g., ['baseline', '0.8', '0.7']\n",
    "\n",
    "# Generate a colormap\n",
    "num_configs = len(configs)\n",
    "colors = cm.tab10(np.linspace(0, 1, num_configs))  # Use 'tab10' for distinct colors\n",
    "\n",
    "# Common styling\n",
    "font = {'family': 'Arial', 'weight': 'bold', 'size': 14}  # Font for labels and titles\n",
    "line_width = 2  # Thickness of lines\n",
    "legend_font_size = 12  # Legend font size\n",
    "\n",
    "# Initialize subplots\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 18))  # Larger plot size for better readability\n",
    "\n",
    "# Plot Time vs Epochs\n",
    "for idx, config in enumerate(configs):\n",
    "    epochs = list(range(1, len(data[config][\"time\"]) + 1))\n",
    "    time_data = data[config][\"time\"]\n",
    "    axes[0].plot(\n",
    "        epochs, time_data, label=f\"{config}\", color=colors[idx], linewidth=line_width\n",
    "    )\n",
    "\n",
    "axes[0].set_xlabel(\"Epochs\", fontdict=font)\n",
    "axes[0].set_ylabel(\"Time\", fontdict=font)\n",
    "axes[0].set_title(\"Time vs Epochs\", fontdict=font)\n",
    "axes[0].legend(fontsize=legend_font_size)\n",
    "axes[0].grid(True, linestyle=\"--\", alpha=0.7)  # Dashed grid lines for clarity\n",
    "\n",
    "# Plot Accuracy vs Epochs\n",
    "for idx, config in enumerate(configs):\n",
    "    epochs = list(range(1, len(data[config][\"accuracy\"]) + 1))\n",
    "    accuracy = data[config][\"accuracy\"]\n",
    "    axes[1].plot(\n",
    "        epochs, accuracy, label=f\"{config}\", color=colors[idx], linewidth=line_width\n",
    "    )\n",
    "\n",
    "axes[1].set_xlabel(\"Epochs\", fontdict=font)\n",
    "axes[1].set_ylabel(\"Accuracy\", fontdict=font)\n",
    "axes[1].set_title(\"Accuracy vs Epochs\", fontdict=font)\n",
    "axes[1].legend(fontsize=legend_font_size)\n",
    "axes[1].grid(True, linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Plot Size vs Epochs\n",
    "for idx, config in enumerate(configs):\n",
    "    epochs = list(range(1, len(data[config][\"size\"]) + 1))\n",
    "    size = data[config][\"size\"]\n",
    "    axes[2].plot(\n",
    "        epochs, size, label=f\"{config}\", color=colors[idx], linewidth=line_width\n",
    "    )\n",
    "\n",
    "axes[2].set_xlabel(\"Epochs\", fontdict=font)\n",
    "axes[2].set_ylabel(\"Size\", fontdict=font)\n",
    "axes[2].set_title(\"Size vs Epochs\", fontdict=font)\n",
    "axes[2].legend(fontsize=legend_font_size)\n",
    "axes[2].grid(True, linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Define the epoch ranges for shading\n",
    "full_dataset_range = (1, 10)  # Replace with the actual range for full dataset training\n",
    "medium_examples_range = (10, 26)  # Replace with the actual range for medium examples\n",
    "hard_examples_range = (26, 40)  # Replace with the actual range for hard examples\n",
    "\n",
    "# Colors for the shaded regions\n",
    "shaded_colors = [\"lightblue\", \"lightgreen\", \"lightcoral\"]\n",
    "\n",
    "# Add shading to each plot\n",
    "for ax in axes:\n",
    "    # Shade full dataset range\n",
    "    ax.axvspan(\n",
    "        full_dataset_range[0],\n",
    "        full_dataset_range[1],\n",
    "        color=shaded_colors[0],\n",
    "        alpha=0.3,\n",
    "        label=\"Full Dataset\"\n",
    "    )\n",
    "    # Shade medium examples range\n",
    "    ax.axvspan(\n",
    "        medium_examples_range[0],\n",
    "        medium_examples_range[1],\n",
    "        color=shaded_colors[1],\n",
    "        alpha=0.3,\n",
    "        label=\"Medium Examples\"\n",
    "    )\n",
    "    # Shade hard examples range\n",
    "    ax.axvspan(\n",
    "        hard_examples_range[0],\n",
    "        hard_examples_range[1],\n",
    "        color=shaded_colors[2],\n",
    "        alpha=0.3,\n",
    "        label=\"Hard Examples\"\n",
    "    )\n",
    "\n",
    "# Add legends for the shaded regions to the first plot\n",
    "axes[0].legend(fontsize=legend_font_size, loc=\"lower left\")\n",
    "axes[1].legend(fontsize=legend_font_size, loc=\"lower right\")\n",
    "axes[2].legend(fontsize=legend_font_size, loc=\"lower left\")\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'./outputs/plots/{isTest}{MODEL_NAME}-{DATA_NAME}-{NUM_CLASS}/proposed-comparison-{MODEL_NAME}-{DATA_NAME}-{NUM_CLASS}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f'\\n\\nRAN MODEL : {isTest}{MODEL_NAME}, DATA: {DATA_NAME}-{NUM_CLASS}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "domianins",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
